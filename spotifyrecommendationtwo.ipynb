{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Songs:\n",
      "                     track_id  \\\n",
      "673    3tInTDUq8wdIMw5ftohmqJ   \n",
      "5444   5HhYHpxwdGTCO5YK7dycoT   \n",
      "80400  2MvCNH9ua0CeOgUQfZf56z   \n",
      "76563  6jtro2UfTOFqgQ6A3OptWJ   \n",
      "62056  0Rs16msoj79XTObU9iEIqd   \n",
      "46861  6b2fIv4A1u9qFDA0qE3CH2   \n",
      "97889  7IrmGMCzgByMVNMpUEOIXI   \n",
      "23097  4VmgXxoTyo1RjJXFK8Ed6g   \n",
      "13983  6KBSVTTmLuR5PT9gpLW1OB   \n",
      "21894  2maIfRJZY51Ls412KzKs6Z   \n",
      "\n",
      "                                            track_name  cluster  \n",
      "673                                   Girls Chase Boys        4  \n",
      "5444                                        My Dearest        7  \n",
      "80400                                         Guzarish        5  \n",
      "76563                                             Soli        5  \n",
      "62056                                         December        3  \n",
      "46861                           Only If I Had One More        4  \n",
      "97889  Então Me Pega (feat. Diego & Arnaldo) - Ao Vivo        4  \n",
      "23097                         Stay The Night - Re-Edit        5  \n",
      "13983                             Strumming & Thinking        1  \n",
      "21894                                       Born Again        4  \n",
      "\n",
      "Recommended Songs:\n",
      "                     track_id                track_name  cluster\n",
      "28052  2umqe74ItZBWCdChsHtXjQ                    U & Me        4\n",
      "28255  5RkJMrhW5aU2zMuJcZUNmh                 Do Better        7\n",
      "80597  7nRFeG20drpHn9CqPuRVJ6     Vizhigalil Vizhigalil        5\n",
      "7586   3xKkwHwX9SN7kblcoY2FCe     I'd Probably Kill You        5\n",
      "62087  1zT20Rgscp6BAqMhMMFFtV                  December        3\n",
      "46317  01N3dypizZMUHKdcsQ02Jo     Only If I Had - Remix        4\n",
      "97528  040SS97cdQhszuY9MNNSkQ                    Os Mió        4\n",
      "23096  2okeBh2MAMVdL1GS8jhxCX  Stay The Night - Re-Edit        5\n",
      "24881  15ZVK7G0a8Ar2UA7uFFAzX                    Groove        1\n",
      "28796  1FaBhUg1WojOEMpTCWUzDQ             Rumors Of War        4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "spotify_df_test = pd.read_csv('/Users/anikasethi/Desktop/test_dataset.csv')\n",
    "spotify_df_test = spotify_df_test.drop_duplicates(subset='track_id', keep='first')\n",
    "\n",
    "# Features to train on (need to be normalized)\n",
    "train_features = ['popularity', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "                  'liveness', 'valence', 'tempo', 'time_signature']\n",
    "\n",
    "# Split the data into training (70%) and testing (30%)\n",
    "train_data, test_data = train_test_split(spotify_df_test, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalize the training data\n",
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_data[train_features])\n",
    "\n",
    "# Apply normalization to the testing data using the same scaler\n",
    "test_features_scaled = scaler.transform(test_data[train_features])\n",
    "\n",
    "# Add normalized features back to the DataFrames\n",
    "train_data[train_features] = train_features_scaled\n",
    "test_data[train_features] = test_features_scaled\n",
    "\n",
    "# Train K-Means with 10 clusters\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "kmeans.fit(train_data[train_features])\n",
    "\n",
    "# Add cluster labels to the training and testing data\n",
    "train_data['cluster'] = kmeans.labels_\n",
    "test_data['cluster'] = kmeans.predict(test_data[train_features])\n",
    "\n",
    "# Randomly select 10 songs from the testing data\n",
    "selected_songs = test_data.sample(n=10, random_state=42)\n",
    "\n",
    "# Generate 10 recommendations\n",
    "recommendations = []\n",
    "used_ids = set()  # Track IDs of already recommended songs\n",
    "\n",
    "for _, song in selected_songs.iterrows():\n",
    "    cluster_label = song['cluster']  # Get the cluster of the selected song\n",
    "    \n",
    "    # Filter songs in the same cluster from the training dataset\n",
    "    cluster_songs = train_data[train_data['cluster'] == cluster_label]\n",
    "    \n",
    "    # Exclude already recommended songs\n",
    "    cluster_songs = cluster_songs[~cluster_songs['track_id'].isin(used_ids)]\n",
    "    \n",
    "    # If the cluster is empty, skip or fallback to another cluster\n",
    "    if cluster_songs.empty:\n",
    "        print(f\"No songs available in cluster {cluster_label} for recommendation.\")\n",
    "        continue\n",
    "    \n",
    "    # Ensure numeric arrays for features\n",
    "    selected_song_features = song[train_features].values.astype(float)\n",
    "    cluster_songs_features = cluster_songs[train_features].values.astype(float)\n",
    "    \n",
    "    # Compute Euclidean distances\n",
    "    distances = np.linalg.norm(cluster_songs_features - selected_song_features, axis=1)\n",
    "    \n",
    "    # Find the index of the closest song\n",
    "    nearest_song_idx = np.argmin(distances)\n",
    "    \n",
    "    # Get the nearest song from the DataFrame\n",
    "    nearest_song = cluster_songs.iloc[nearest_song_idx]\n",
    "    recommendations.append(nearest_song)\n",
    "    \n",
    "    # Add the recommended song's ID to the used list\n",
    "    used_ids.add(nearest_song['track_id'])\n",
    "\n",
    "# Combine all recommendations into a single DataFrame\n",
    "recommended_songs = pd.DataFrame(recommendations)\n",
    "\n",
    "# Display the selected and recommended songs\n",
    "print(\"\\nSelected Songs:\")\n",
    "print(selected_songs[['track_id', 'track_name', 'cluster']])\n",
    "\n",
    "# Check if recommendations are empty\n",
    "if recommended_songs.empty:\n",
    "    print(\"No recommendations could be made.\")\n",
    "else:\n",
    "    print(\"\\nRecommended Songs:\")\n",
    "    print(recommended_songs[['track_id', 'track_name', 'cluster']])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
